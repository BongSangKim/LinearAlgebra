{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim \n",
    "from os import walk\n",
    "\n",
    "file_list = []\n",
    "current_path = \"./aclImdb/test/neg/\"\n",
    "for (dirpath, dirnames, filenames) in walk(current_path):\n",
    "    file_list.extend(filenames)\n",
    "    break\n",
    "\n",
    "def read_input(current_path, file_list):\n",
    "    for i in range(len(file_list)):\n",
    "        with open(current_path + file_list[i]) as file:\n",
    "            for j, line in enumerate(file):\n",
    "                yield gensim.utils.simple_preprocess(line)\n",
    "\n",
    "document = list(read_input(current_path, file_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-05-01 10:54:45,839 : WARNING : consider setting layer size to a multiple of 4 for greater performance\n",
      "2019-05-01 10:54:45,840 : INFO : collecting all words and their counts\n",
      "2019-05-01 10:54:45,841 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2019-05-01 10:54:46,143 : INFO : PROGRESS: at sentence #10000, processed 2211040 words, keeping 47953 word types\n",
      "2019-05-01 10:54:46,220 : INFO : collected 52418 word types from a corpus of 2754003 raw words and 12500 sentences\n",
      "2019-05-01 10:54:46,221 : INFO : Loading a fresh vocabulary\n",
      "2019-05-01 10:54:46,277 : INFO : min_count=2 retains 33038 unique words (63% of original 52418, drops 19380)\n",
      "2019-05-01 10:54:46,278 : INFO : min_count=2 leaves 2734623 word corpus (99% of original 2754003, drops 19380)\n",
      "2019-05-01 10:54:46,352 : INFO : deleting the raw counts dictionary of 52418 items\n",
      "2019-05-01 10:54:46,354 : INFO : sample=0.001 downsamples 50 most-common words\n",
      "2019-05-01 10:54:46,355 : INFO : downsampling leaves estimated 2078147 word corpus (76.0% of prior 2734623)\n",
      "2019-05-01 10:54:46,441 : INFO : estimated required memory for 33038 words and 50 dimensions: 29734200 bytes\n",
      "2019-05-01 10:54:46,442 : INFO : resetting layer weights\n",
      "2019-05-01 10:54:46,735 : INFO : training model with 4 workers on 33038 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=10\n",
      "2019-05-01 10:54:47,741 : INFO : EPOCH 1 - PROGRESS: at 89.16% examples, 1855526 words/s, in_qsize 7, out_qsize 0\n",
      "2019-05-01 10:54:47,851 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-05-01 10:54:47,858 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-05-01 10:54:47,860 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-05-01 10:54:47,861 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-05-01 10:54:47,863 : INFO : EPOCH - 1 : training on 2754003 raw words (2078443 effective words) took 1.1s, 1851490 effective words/s\n",
      "2019-05-01 10:54:48,872 : INFO : EPOCH 2 - PROGRESS: at 86.16% examples, 1785222 words/s, in_qsize 7, out_qsize 0\n",
      "2019-05-01 10:54:49,035 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-05-01 10:54:49,041 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-05-01 10:54:49,043 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-05-01 10:54:49,045 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-05-01 10:54:49,046 : INFO : EPOCH - 2 : training on 2754003 raw words (2077906 effective words) took 1.2s, 1760170 effective words/s\n",
      "2019-05-01 10:54:50,054 : INFO : EPOCH 3 - PROGRESS: at 75.60% examples, 1566694 words/s, in_qsize 7, out_qsize 0\n",
      "2019-05-01 10:54:50,360 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-05-01 10:54:50,361 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-05-01 10:54:50,370 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-05-01 10:54:50,371 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-05-01 10:54:50,373 : INFO : EPOCH - 3 : training on 2754003 raw words (2077971 effective words) took 1.3s, 1569274 effective words/s\n",
      "2019-05-01 10:54:51,376 : INFO : EPOCH 4 - PROGRESS: at 78.51% examples, 1633813 words/s, in_qsize 7, out_qsize 0\n",
      "2019-05-01 10:54:51,661 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-05-01 10:54:51,664 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-05-01 10:54:51,670 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-05-01 10:54:51,671 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-05-01 10:54:51,672 : INFO : EPOCH - 4 : training on 2754003 raw words (2078340 effective words) took 1.3s, 1602301 effective words/s\n",
      "2019-05-01 10:54:52,680 : INFO : EPOCH 5 - PROGRESS: at 78.18% examples, 1623954 words/s, in_qsize 6, out_qsize 1\n",
      "2019-05-01 10:54:52,946 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-05-01 10:54:52,950 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-05-01 10:54:52,956 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-05-01 10:54:52,957 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-05-01 10:54:52,958 : INFO : EPOCH - 5 : training on 2754003 raw words (2078285 effective words) took 1.3s, 1623521 effective words/s\n",
      "2019-05-01 10:54:52,960 : INFO : training on a 13770015 raw words (10390945 effective words) took 6.2s, 1669476 effective words/s\n",
      "2019-05-01 10:54:52,977 : WARNING : Effective 'alpha' higher than previous training cycles\n",
      "2019-05-01 10:54:52,978 : INFO : training model with 4 workers on 33038 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=10\n",
      "2019-05-01 10:54:53,982 : INFO : EPOCH 1 - PROGRESS: at 70.73% examples, 1470589 words/s, in_qsize 7, out_qsize 0\n",
      "2019-05-01 10:54:54,396 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-05-01 10:54:54,398 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-05-01 10:54:54,401 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-05-01 10:54:54,405 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-05-01 10:54:54,406 : INFO : EPOCH - 1 : training on 2754003 raw words (2078690 effective words) took 1.4s, 1459159 effective words/s\n",
      "2019-05-01 10:54:55,415 : INFO : EPOCH 2 - PROGRESS: at 72.85% examples, 1508833 words/s, in_qsize 7, out_qsize 0\n",
      "2019-05-01 10:54:55,756 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-05-01 10:54:55,762 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-05-01 10:54:55,763 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-05-01 10:54:55,764 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-05-01 10:54:55,765 : INFO : EPOCH - 2 : training on 2754003 raw words (2077709 effective words) took 1.4s, 1534299 effective words/s\n",
      "2019-05-01 10:54:56,769 : INFO : EPOCH 3 - PROGRESS: at 77.08% examples, 1605356 words/s, in_qsize 7, out_qsize 0\n",
      "2019-05-01 10:54:57,066 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-05-01 10:54:57,067 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-05-01 10:54:57,070 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-05-01 10:54:57,072 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-05-01 10:54:57,073 : INFO : EPOCH - 3 : training on 2754003 raw words (2078784 effective words) took 1.3s, 1593755 effective words/s\n",
      "2019-05-01 10:54:58,076 : INFO : EPOCH 4 - PROGRESS: at 76.70% examples, 1596966 words/s, in_qsize 7, out_qsize 0\n",
      "2019-05-01 10:54:58,351 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-05-01 10:54:58,353 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-05-01 10:54:58,359 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-05-01 10:54:58,361 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-05-01 10:54:58,362 : INFO : EPOCH - 4 : training on 2754003 raw words (2077427 effective words) took 1.3s, 1615112 effective words/s\n",
      "2019-05-01 10:54:59,368 : INFO : EPOCH 5 - PROGRESS: at 91.68% examples, 1902468 words/s, in_qsize 7, out_qsize 0\n",
      "2019-05-01 10:54:59,447 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-05-01 10:54:59,452 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-05-01 10:54:59,456 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-05-01 10:54:59,458 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-05-01 10:54:59,459 : INFO : EPOCH - 5 : training on 2754003 raw words (2078357 effective words) took 1.1s, 1898511 effective words/s\n",
      "2019-05-01 10:55:00,465 : INFO : EPOCH 6 - PROGRESS: at 82.60% examples, 1720014 words/s, in_qsize 7, out_qsize 0\n",
      "2019-05-01 10:55:00,640 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-05-01 10:55:00,648 : INFO : worker thread finished; awaiting finish of 2 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-05-01 10:55:00,650 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-05-01 10:55:00,652 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-05-01 10:55:00,653 : INFO : EPOCH - 6 : training on 2754003 raw words (2078176 effective words) took 1.2s, 1747890 effective words/s\n",
      "2019-05-01 10:55:01,661 : INFO : EPOCH 7 - PROGRESS: at 85.05% examples, 1773255 words/s, in_qsize 8, out_qsize 0\n",
      "2019-05-01 10:55:01,858 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-05-01 10:55:01,859 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-05-01 10:55:01,867 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-05-01 10:55:01,868 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-05-01 10:55:01,869 : INFO : EPOCH - 7 : training on 2754003 raw words (2078001 effective words) took 1.2s, 1718472 effective words/s\n",
      "2019-05-01 10:55:02,873 : INFO : EPOCH 8 - PROGRESS: at 83.59% examples, 1743778 words/s, in_qsize 7, out_qsize 0\n",
      "2019-05-01 10:55:03,082 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-05-01 10:55:03,085 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-05-01 10:55:03,091 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-05-01 10:55:03,092 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-05-01 10:55:03,093 : INFO : EPOCH - 8 : training on 2754003 raw words (2078371 effective words) took 1.2s, 1702701 effective words/s\n",
      "2019-05-01 10:55:04,098 : INFO : EPOCH 9 - PROGRESS: at 81.62% examples, 1696706 words/s, in_qsize 7, out_qsize 0\n",
      "2019-05-01 10:55:04,310 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-05-01 10:55:04,316 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-05-01 10:55:04,319 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-05-01 10:55:04,321 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-05-01 10:55:04,322 : INFO : EPOCH - 9 : training on 2754003 raw words (2078542 effective words) took 1.2s, 1694860 effective words/s\n",
      "2019-05-01 10:55:05,325 : INFO : EPOCH 10 - PROGRESS: at 85.48% examples, 1780593 words/s, in_qsize 7, out_qsize 0\n",
      "2019-05-01 10:55:05,470 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-05-01 10:55:05,474 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-05-01 10:55:05,476 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-05-01 10:55:05,480 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-05-01 10:55:05,481 : INFO : EPOCH - 10 : training on 2754003 raw words (2078267 effective words) took 1.2s, 1796654 effective words/s\n",
      "2019-05-01 10:55:05,482 : INFO : training on a 27540030 raw words (20782324 effective words) took 12.5s, 1662094 effective words/s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(20782324, 27540030)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Imdb_review_model = gensim.models.Word2Vec (document, size=50, window=10, min_count=2, workers=4)\n",
    "Imdb_review_model.train(document, total_examples=len(document), epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('intriguing', 0.7861724495887756),\n",
       " ('exciting', 0.7413128614425659),\n",
       " ('odd', 0.7387148141860962),\n",
       " ('effective', 0.7348339557647705),\n",
       " ('realistic', 0.6612774133682251),\n",
       " ('promising', 0.6301883459091187)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Imdb_review_model.wv.most_similar(positive = ['interesting'], topn=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('cents', 0.5387125611305237),\n",
       " ('mart', 0.5345513224601746),\n",
       " ('stores', 0.5297784805297852),\n",
       " ('wal', 0.5278729796409607),\n",
       " ('grocery', 0.5252329111099243),\n",
       " ('sale', 0.516481339931488)]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Imdb_review_model.wv.most_similar(negative = ['uninteresting'], topn=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the 163308\n"
     ]
    }
   ],
   "source": [
    "maxcount = 0\n",
    "maxword = str()\n",
    "for word, obj in Imdb_review_model.wv.vocab.items():\n",
    "    if maxcount < obj.count:\n",
    "        maxcount = obj.count\n",
    "        maxword = word\n",
    "print(maxword, maxcount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the 163308\n",
      "and 73415\n",
      "of 68296\n",
      "to 67828\n",
      "br 51361\n",
      "is 49167\n",
      "it 47331\n",
      "in 43776\n",
      "this 40432\n",
      "that 36646\n",
      "was 25978\n",
      "movie 25148\n",
      "for 21307\n",
      "but 21037\n",
      "with 20770\n",
      "as 20018\n",
      "film 18376\n",
      "you 18041\n",
      "on 17117\n",
      "not 16087\n",
      "have 15468\n",
      "are 14527\n",
      "be 14282\n",
      "he 13231\n",
      "one 13145\n",
      "they 12884\n",
      "at 12132\n",
      "all 11776\n",
      "his 11676\n",
      "so 11306\n",
      "like 11217\n",
      "there 10532\n",
      "just 10455\n",
      "an 10240\n",
      "by 10190\n",
      "or 10084\n",
      "from 9846\n",
      "if 9761\n",
      "who 9655\n",
      "out 9009\n",
      "about 8735\n",
      "what 8541\n",
      "some 8353\n",
      "no 7916\n",
      "even 7563\n",
      "has 7455\n",
      "can 7441\n",
      "her 7408\n",
      "bad 7325\n",
      "good 7305\n",
      "would 6971\n",
      "up 6904\n",
      "when 6771\n",
      "only 6595\n",
      "more 6549\n",
      "she 6209\n",
      "time 6147\n",
      "really 6092\n",
      "my 5986\n",
      "had 5860\n",
      "were 5816\n",
      "very 5796\n",
      "me 5659\n",
      "which 5581\n",
      "see 5301\n",
      "don 5259\n",
      "their 5210\n",
      "do 5198\n",
      "get 5096\n",
      "we 5062\n",
      "much 5040\n",
      "been 5009\n",
      "story 4976\n",
      "than 4974\n",
      "because 4768\n",
      "people 4662\n",
      "how 4646\n",
      "make 4633\n",
      "could 4615\n",
      "then 4558\n",
      "into 4508\n",
      "any 4469\n",
      "other 4383\n",
      "well 4283\n",
      "made 4260\n",
      "movies 4232\n",
      "them 4189\n",
      "too 4084\n",
      "plot 4059\n",
      "first 4046\n",
      "acting 4031\n",
      "him 3924\n",
      "most 3895\n",
      "will 3845\n",
      "way 3791\n",
      "characters 3753\n",
      "after 3686\n",
      "watch 3670\n",
      "off 3642\n",
      "also 3576\n"
     ]
    }
   ],
   "source": [
    "wordlist = []\n",
    "count = []\n",
    "for word, obj in Imdb_review_model.wv.vocab.items():\n",
    "    wordlist.append(word)\n",
    "    count.append(obj.count)\n",
    "for _ in range(100):\n",
    "    idx = count.index(max(count))\n",
    "    print(wordlist[idx], max(count))\n",
    "    del count[idx]\n",
    "    del wordlist[idx]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
